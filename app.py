import streamlit as st
import zipfile, io, re, unicodedata
import pandas as pd
from bs4 import BeautifulSoup

# ì„ íƒì  ì¸ì½”ë”© íƒì§€
try:
    import chardet
except ImportError:
    chardet = None

# =============== ê¸°ë³¸ ì„¤ì • ===============
st.set_page_config(page_title="XML í‚¤ì›Œë“œ ê²€ìƒ‰ê¸°", page_icon="ğŸ”", layout="wide")
st.title("ğŸ” XML ZIP ë¬¸ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ê¸° (ì¬ê·€ ZIP + DART ë§í¬)")

st.markdown("""
ì—…ë¡œë“œí•œ ZIP íŒŒì¼(ì¤‘ì²© ZIP í¬í•¨)ì—ì„œ XML/HTML/TXTë¥¼ ë¶„ì„í•´  
ì…ë ¥í•œ **í‚¤ì›Œë“œ**ê°€ í¬í•¨ëœ ë¬¸ì„œë¥¼ ì°¾ê³ , ê°€ëŠ¥í•˜ë©´ **DART ì›ë¬¸ ë§í¬**ê¹Œì§€ ì œê³µí•©ë‹ˆë‹¤.
""")

DART_BASE = "https://dart.fss.or.kr/dsaf001/main.do?rcpNo="

# =============== ìœ í‹¸: ì¸ì½”ë”©/í…ìŠ¤íŠ¸ ì¶”ì¶œ ===============
def try_decode(raw: bytes) -> str:
    for enc in ("utf-8", "utf-8-sig", "cp949", "euc-kr"):
        try:
            return raw.decode(enc)
        except Exception:
            continue
    if chardet:
        det = chardet.detect(raw)
        enc = (det.get("encoding") or "").lower()
        if enc:
            try:
                return raw.decode(enc, errors="replace")
            except Exception:
                pass
    return raw.decode("utf-8", errors="replace")

def extract_text(file_bytes: bytes) -> str:
    txt = try_decode(file_bytes)
    soup = None
    for parser in ("lxml-xml", "lxml", "html.parser"):
        try:
            soup = BeautifulSoup(txt, parser)
            if soup and soup.text.strip():
                break
        except Exception:
            continue
    if not soup:
        return ""
    for tag in soup(["script", "style"]):
        tag.decompose()
    text = soup.get_text(" ", strip=True)
    text = unicodedata.normalize("NFKC", text)
    text = re.sub(r"[\u200b-\u200f\u202a-\u202e]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# =============== ìœ í‹¸: rcpNo(ì ‘ìˆ˜ë²ˆí˜¸) ì¶”ì¶œ ===============
_rcpno_pat = re.compile(r"(?:<rcept_no>\s*(20\d{12})\s*</rcept_no>)|(?:\b(20\d{12})\b)", re.IGNORECASE)

def find_rcpno_from_path(path: str) -> str | None:
    # ê²½ë¡œ/íŒŒì¼ëª…ì—ì„œ 14ìë¦¬ ì ‘ìˆ˜ë²ˆí˜¸ ì°¾ê¸° (2000ë…„ëŒ€ í˜•ì‹ ê°€ì •)
    m = re.search(r"\b(20\d{12})\b", path)
    return m.group(1) if m else None

def find_rcpno_from_text(text: str) -> str | None:
    # <rcept_no>2023... </rcept_no> ë˜ëŠ” ê·¸ëƒ¥ 14ìë¦¬ ìˆ«ì
    m = _rcpno_pat.search(text)
    if not m:
        return None
    return m.group(1) or m.group(2)

def make_dart_link(rcpno: str | None) -> str:
    return f"{DART_BASE}{rcpno}" if rcpno else ""

# =============== ì¬ê·€ ZIP íƒìƒ‰ ===============
def extract_texts_from_zip(zf_bytes, keywords, results, parent=""):
    try:
        with zipfile.ZipFile(io.BytesIO(zf_bytes), "r") as zf:
            for name in zf.namelist():
                path = f"{parent}/{name}" if parent else name

                # ë‚´ë¶€ ZIP â†’ ì¬ê·€
                if name.lower().endswith(".zip"):
                    try:
                        inner_bytes = zf.read(name)
                        extract_texts_from_zip(inner_bytes, keywords, results, parent=path)
                    except Exception:
                        continue

                # ëŒ€ìƒ í™•ì¥ì
                elif name.lower().endswith((".xml", ".xbrl", ".htm", ".html", ".txt")):
                    try:
                        raw = zf.read(name)
                    except Exception:
                        continue

                    text_content = extract_text(raw)
                    if not text_content:
                        continue

                    # rcpNo ì¶”ì¶œ (ìš°ì„ ìˆœìœ„: ê²½ë¡œ â†’ ë³¸ë¬¸)
                    rcpno = find_rcpno_from_path(path) or find_rcpno_from_text(text_content)
                    dart_link = make_dart_link(rcpno)

                    found_words, snippets = [], []
                    for kw in keywords:
                        pat = re.compile(r".{0,50}" + re.escape(kw) + r".{0,50}", re.IGNORECASE)
                        matches = pat.findall(text_content)
                        if matches:
                            found_words.append(kw)
                            for m in matches[:3]:
                                snippets.append(f"...{m}...")

                    if found_words:
                        results.append({
                            "íŒŒì¼ê²½ë¡œ": path,
                            "ì¼ì¹˜ í‚¤ì›Œë“œ": ", ".join(sorted(set(found_words))),
                            "ì¼ì¹˜ íšŸìˆ˜": len(snippets),
                            "ë¬¸ì¥ ì¼ë¶€": "\n".join(snippets),
                            "DARTë§í¬": dart_link
                        })
    except zipfile.BadZipFile:
        pass

# =============== UI ===============
uploaded_file = st.file_uploader("ğŸ“‚ ZIP íŒŒì¼ ì—…ë¡œë“œ", type=["zip"])
keywords_input = st.text_input("ğŸ” ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„ ê°€ëŠ¥)", placeholder="ì˜ˆ: ì„ì›, ESG, í’ˆì§ˆ, ì§€ì†ê°€ëŠ¥")
search_button = st.button("ê²€ìƒ‰ ì‹œì‘ ğŸ”")

if search_button:
    if not uploaded_file:
        st.warning("âš ï¸ ZIP íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
    elif not keywords_input.strip():
        st.warning("âš ï¸ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        keywords = [kw.strip() for kw in keywords_input.split(",") if kw.strip()]
        results = []
        try:
            file_bytes = uploaded_file.read()
            extract_texts_from_zip(file_bytes, keywords, results)
        except Exception as e:
            st.error(f"ZIP ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        if results:
            df = pd.DataFrame(results)

            st.success(f"âœ… ì´ {len(df)}ê°œ ë¬¸ì„œì—ì„œ í‚¤ì›Œë“œ ë°œê²¬")
            st.dataframe(
                df,
                use_container_width=True,
                column_config={
                    "íŒŒì¼ê²½ë¡œ": st.column_config.TextColumn("íŒŒì¼ ê²½ë¡œ", width="medium"),
                    "ì¼ì¹˜ í‚¤ì›Œë“œ": st.column_config.TextColumn("ì¼ì¹˜ í‚¤ì›Œë“œ"),
                    "ì¼ì¹˜ íšŸìˆ˜": st.column_config.NumberColumn("ì¼ì¹˜ íšŸìˆ˜"),
                    "ë¬¸ì¥ ì¼ë¶€": st.column_config.TextColumn("ë¬¸ì¥ ì¼ë¶€", width="large"),
                    # âœ… í´ë¦­ ê°€ëŠ¥í•œ ë§í¬
                    "DARTë§í¬": st.column_config.LinkColumn("DART ë³´ê³ ì„œ", display_text="ë°”ë¡œë³´ê¸°")
                }
            )

            csv = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "ğŸ“Š ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="keyword_search_results.csv",
                mime="text/csv",
                use_container_width=True
            )
        else:
            st.warning("âŒ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
else:
    st.info("ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•œ ë’¤ **[ê²€ìƒ‰ ì‹œì‘]** ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
