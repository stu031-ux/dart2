import streamlit as st
import zipfile, io, re
import pandas as pd
from bs4 import BeautifulSoup

st.title("ğŸ“‚ ESG ê´€ë ¨ ë³´ê³ ì„œ íƒìƒ‰ê¸°")

keywords = ["ESG", "ì§€ì†ê°€ëŠ¥ê²½ì˜", "í™˜ê²½", "ì‚¬íšŒ", "ê±°ë²„ë„ŒìŠ¤",
            "sustainability", "environment", "social", "governance"]

uploaded_file = st.file_uploader("ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["zip"])

if uploaded_file:
    results = []
    with zipfile.ZipFile(uploaded_file, "r") as zf:
        for name in zf.namelist():
            if not name.lower().endswith(".xml"):
                continue
            with zf.open(name) as fp:
                try:
                    text = fp.read().decode("utf-8", errors="ignore")
                except:
                    continue
                soup = BeautifulSoup(text, "xml")
                text_content = soup.get_text(" ", strip=True)
                found = [kw for kw in keywords if kw.lower() in text_content.lower()]
                if found:
                    # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ì¼ë¶€ ì¶”ì¶œ
                    snippet = ""
                    for kw in found:
                        m = re.search(r".{0,40}" + kw + r".{0,40}", text_content, re.IGNORECASE)
                        if m:
                            snippet += f"...{m.group(0)}..."
                    results.append({"íŒŒì¼ëª…": name, "ì¼ì¹˜ í‚¤ì›Œë“œ": ", ".join(found), "ë¬¸ì¥ ì¼ë¶€": snippet})
    
    if results:
        df = pd.DataFrame(results)
        st.dataframe(df, use_container_width=True)
        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“Š ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="esg_ê²€ìƒ‰ê²°ê³¼.csv", mime="text/csv")
    else:
        st.warning("ESG ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
