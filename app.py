import streamlit as st
import zipfile, io, re, unicodedata
import pandas as pd
from bs4 import BeautifulSoup

# ì„ íƒì  ì¸ì½”ë”© íƒì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import chardet
except ImportError:
    chardet = None

# ----------------------------------
# ê¸°ë³¸ ì„¤ì •
# ----------------------------------
st.set_page_config(page_title="XML í‚¤ì›Œë“œ ê²€ìƒ‰ê¸°", page_icon="ğŸ”", layout="wide")
st.title("ğŸ” XML ZIP ë¬¸ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ê¸° (ì¬ê·€ ZIP ì§€ì› ë²„ì „)")

st.markdown("""
ì—…ë¡œë“œí•œ ZIP íŒŒì¼ ì•ˆì˜ XML/HTML ë¬¸ì„œë¥¼ ëª¨ë‘ ë¶„ì„í•´,  
**ì…ë ¥í•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œ**ë¥¼ ì°¾ì•„ í‘œì‹œí•©ë‹ˆë‹¤.  
(â€» ZIP ì•ˆì— ë˜ ZIPì´ ë“¤ì–´ìˆì–´ë„ ëª¨ë‘ ìë™ íƒìƒ‰í•©ë‹ˆë‹¤)
""")

# ----------------------------------
# í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
# ----------------------------------
def try_decode(raw: bytes) -> str:
    """ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„ë¡œ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ ë””ì½”ë”©"""
    for enc in ("utf-8", "utf-8-sig", "cp949", "euc-kr"):
        try:
            return raw.decode(enc)
        except Exception:
            continue
    if chardet:
        det = chardet.detect(raw)
        enc = (det.get("encoding") or "").lower()
        if enc:
            try:
                return raw.decode(enc, errors="replace")
            except Exception:
                pass
    return raw.decode("utf-8", errors="replace")

def extract_text(file_bytes: bytes) -> str:
    """XML/HTML/TXT ë“±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ"""
    txt = try_decode(file_bytes)
    soup = None
    for parser in ("lxml-xml", "lxml", "html.parser"):
        try:
            soup = BeautifulSoup(txt, parser)
            if soup and soup.text.strip():
                break
        except Exception:
            continue
    if not soup:
        return ""
    for tag in soup(["script", "style"]):
        tag.decompose()
    text = soup.get_text(" ", strip=True)
    text = unicodedata.normalize("NFKC", text)
    text = re.sub(r"[\u200b-\u200f\u202a-\u202e]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# ----------------------------------
# ì¬ê·€ ZIP íƒìƒ‰ í•¨ìˆ˜
# ----------------------------------
def extract_texts_from_zip(zf_bytes, keywords, results, parent=""):
    """ZIP íŒŒì¼ ë‚´ë¶€ì˜ XML/HTML íŒŒì¼ê³¼ ì¤‘ì²© ZIPê¹Œì§€ ì¬ê·€ íƒìƒ‰"""
    try:
        with zipfile.ZipFile(io.BytesIO(zf_bytes), "r") as zf:
            for name in zf.namelist():
                path = f"{parent}/{name}" if parent else name
                # ë‚´ë¶€ ZIP ì¬ê·€ íƒìƒ‰
                if name.lower().endswith(".zip"):
                    try:
                        inner_bytes = zf.read(name)
                        extract_texts_from_zip(inner_bytes, keywords, results, parent=path)
                    except Exception:
                        continue
                # XML/HTML íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                elif name.lower().endswith((".xml", ".xbrl", ".htm", ".html", ".txt")):
                    try:
                        raw = zf.read(name)
                    except Exception:
                        continue
                    text_content = extract_text(raw)
                    if not text_content:
                        continue

                    found_words, snippets = [], []
                    for kw in keywords:
                        pattern = re.compile(r".{0,50}" + re.escape(kw) + r".{0,50}", re.IGNORECASE)
                        matches = pattern.findall(text_content)
                        if matches:
                            found_words.append(kw)
                            for m in matches[:3]:
                                snippets.append(f"...{m}...")

                    if found_words:
                        results.append({
                            "íŒŒì¼ê²½ë¡œ": path,
                            "ì¼ì¹˜ í‚¤ì›Œë“œ": ", ".join(found_words),
                            "ì¼ì¹˜ íšŸìˆ˜": len(snippets),
                            "ë¬¸ì¥ ì¼ë¶€": "\n".join(snippets)
                        })
    except zipfile.BadZipFile:
        pass

# ----------------------------------
# Streamlit UI
# ----------------------------------
uploaded_file = st.file_uploader("ğŸ“‚ ZIP íŒŒì¼ ì—…ë¡œë“œ", type=["zip"])
keywords_input = st.text_input("ğŸ” ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„ ê°€ëŠ¥)", placeholder="ì˜ˆ: ì„ì›, ESG, í’ˆì§ˆ, ì§€ì†ê°€ëŠ¥")

search_button = st.button("ê²€ìƒ‰ ì‹œì‘ ğŸ”")

if search_button:
    if not uploaded_file:
        st.warning("âš ï¸ ZIP íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
    elif not keywords_input.strip():
        st.warning("âš ï¸ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        keywords = [kw.strip() for kw in keywords_input.split(",") if kw.strip()]
        results = []
        progress = st.progress(0, text="ZIP êµ¬ì¡° íƒìƒ‰ ì¤‘...")

        try:
            file_bytes = uploaded_file.read()
            extract_texts_from_zip(file_bytes, keywords, results)
        except Exception as e:
            st.error(f"ZIP íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ----------------------------------
        # ê²°ê³¼ í‘œì‹œ
        # ----------------------------------
        if results:
            df = pd.DataFrame(results)
            st.success(f"âœ… ì´ {len(df)}ê°œ ë¬¸ì„œì—ì„œ í‚¤ì›Œë“œ ë°œê²¬")
            st.dataframe(df, use_container_width=True)

            csv = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "ğŸ“Š ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="keyword_search_results.csv",
                mime="text/csv",
                use_container_width=True
            )
        else:
            st.warning("âŒ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
else:
    st.info("ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•œ ë’¤ **[ê²€ìƒ‰ ì‹œì‘]** ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
